{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1cfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ°Ô∏è  Initializing Guild Interface AI...\n",
      "üî¥ ERROR: Protocol file not found at '_Admin & Core Docs/Protocols-Frameworks/prompts/guild_oracle_prompt.md'.\n",
      "‚úÖ  Context file loaded: _Admin & Core Docs/Protocols-Frameworks/Copilot_Context_Protocol.md\n",
      "‚úÖ Protocol file found and loaded from: C:\\Local Working Files\\GitHub\\chiron-guild-core\\notebooks\\..\\_Admin & Core Docs/Protocols-Frameworks/Copilot_Context_Protocol.md\n",
      "üü° INFO: No previous history found at chat_logs/portfolio_project_chat.json. Starting a new session.\n",
      "üî¥  Initialization Failed. One or more core protocol files could not be loaded. Please check errors above.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup & Initialization (Local Environment Version)\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# --- Configuration ---\n",
    "# Load environment variables from the .env file in the root directory\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"üî¥ ERROR: GEMINI_API_KEY not found in .env file.\")\n",
    "    print(\"Please create a .env file in the repository root with GEMINI_API_KEY='your-key'.\")\n",
    "else:\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "# --- Guild Protocol Functions ---\n",
    "\n",
    "def load_protocol_file(file_path):\n",
    "    \"\"\"Loads a specific protocol document from the repository.\"\"\"\n",
    "    try:\n",
    "        # Use a relative path assuming the notebook is in the `notebooks` dir\n",
    "        # Adjust if your structure is different\n",
    "        full_path = os.path.join(\"..\", file_path)\n",
    "        if not os.path.exists(full_path):\n",
    "             # Fallback to checking the root dir\n",
    "             full_path = file_path\n",
    "        \n",
    "        with open(full_path, 'r', encoding='utf-8') as f:\n",
    "            print(f\"‚úÖ  Context file loaded: {file_path}\")\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"üî¥ ERROR: Protocol file not found at '{file_path}'.\")\n",
    "        return None\n",
    "\n",
    "def save_chat_history(chat_session, file_path):\n",
    "    \"\"\"Saves the chat history to a JSON file.\"\"\"\n",
    "    history = [\n",
    "        {'role': msg.role, 'parts': [part.text for part in msg.parts]}\n",
    "        for msg in chat_session.history\n",
    "    ]\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(history, f, indent=2)\n",
    "        print(f\"‚úÖ Chat history saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"üî¥ ERROR saving history: {e}\")\n",
    "\n",
    "def load_chat_history(file_path):\n",
    "    \"\"\"Loads a chat history from a JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"üü° INFO: No previous history found at {file_path}. Starting a new session.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"üî¥ ERROR loading history: {e}\")\n",
    "        return None\n",
    "\n",
    "# The full, corrected function in Cell 1\n",
    "\n",
    "def initialize_guild_chat(system_instruction, history=None):\n",
    "    \"\"\"Initializes a new chat session with system instruction and optional history.\"\"\"\n",
    "    \n",
    "    # Define the generation_config for more detailed responses\n",
    "    generation_config = {\n",
    "      \"temperature\": 0.7,\n",
    "      \"top_p\": 1,\n",
    "      \"top_k\": 32,\n",
    "      \"max_output_tokens\": 8192,\n",
    "    }\n",
    "\n",
    "    # This is the corrected line\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-2.5-flash-preview-05-20\",\n",
    "        system_instruction=system_instruction,\n",
    "        generation_config=generation_config\n",
    "    )\n",
    "    \n",
    "    # Pass the loaded history to the start_chat method\n",
    "    chat = model.start_chat(history=history if history else None)\n",
    "    return chat\n",
    "    \n",
    "    # Pass the loaded history to the start_chat method\n",
    "    chat = model.start_chat(history=history if history else None)\n",
    "    return chat\n",
    "    \n",
    "    generation_config = {\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 1,\n",
    "        \"top_k\": 32,\n",
    "        \"max_output_tokens\": 8192, # Increase the max token output significantly\n",
    "}\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-2.5-flash-preview-05-20\", # Corrected Model Name\n",
    "        system_instruction=system_instruction,\n",
    "        generation_config=generation_config\n",
    "    )\n",
    "    chat = model.start_chat()\n",
    "    return chat\n",
    "\n",
    "# --- Main Initialization Step ---\n",
    "print(\"üõ°Ô∏è  Initializing Guild Interface AI...\")\n",
    "\n",
    "ORACLE_PROMPT_PATH = \"_Admin & Core Docs/Protocols-Frameworks/guild_oracle_prompt.md\"\n",
    "COPILOT_CONTEXT_PATH = \"_Admin & Core Docs/Protocols-Frameworks/Copilot_Context_Protocol.md\"\n",
    "\n",
    "oracle_persona_prompt = load_protocol_file(ORACLE_PROMPT_PATH)\n",
    "copilot_foundational_context = load_protocol_file(COPILOT_CONTEXT_PATH)\n",
    "\n",
    "guild_system_protocol = load_system_instruction()\n",
    "loaded_history = load_chat_history('chat_logs/portfolio_project_chat.json') \n",
    "\n",
    "# Combine the two prompts into a single, comprehensive system instruction\n",
    "if oracle_persona_prompt and copilot_foundational_context:\n",
    "    full_system_instruction = f\"\"\"\n",
    "{oracle_persona_prompt}\n",
    "\n",
    "---\n",
    "## Supplemental Foundational Context\n",
    "\n",
    "Below is the foundational context for the Chiron Guild, which you must use to inform all your responses.\n",
    "\n",
    "{copilot_foundational_context}\n",
    "\"\"\"\n",
    "    \n",
    "    # LOAD a specific chat history if desired (optional)\n",
    "    # loaded_history = load_chat_history('chat_logs/your_chat.json') \n",
    "    loaded_history = \"chat_logs/portfolio_project_chat.json\" \n",
    "\n",
    "    # Pass the combined instruction and optional history to the session\n",
    "    guild_chat_session = initialize_guild_chat(full_system_instruction, history=loaded_history)\n",
    "    \n",
    "    if guild_chat_session:\n",
    "        print(\"‚úÖ  Initialization Complete. Oracle is calibrated and online.\")\n",
    "        print(\"‚û°Ô∏è  Proceed to run the UI cells to begin the chat session.\")\n",
    "else:\n",
    "    print(\"üî¥  Initialization Failed. One or more core protocol files could not be loaded. Please check errors above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9647e48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    .widget-text textarea { width: 100% !important; }\n",
       "    .widget-button button { background-color: #4CAF50 !important; color: white !important; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ  Chat Interface Initialized. Enter your prompt below.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2edede0131a4d309f6c5ed289c36420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76c0f1495b74201832919abb68104e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', placeholder='Enter your message...'), Button(description='Send', style=ButtonSty‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95b98e7302c4cfb918a2f1a60804159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<p><i>‚ö´Ô∏è [Guild AI]: Compiling response...</i></p>', layout=Layout(display='none'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 2: UI Setup\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Create the UI components\n",
    "chat_history_view = widgets.Output(layout={'border': '1px solid black', 'height': '400px', 'overflow_y': 'auto'})\n",
    "prompt_input = widgets.Text(placeholder='Enter your message...')\n",
    "send_button = widgets.Button(description='Send')\n",
    "loading_spinner = widgets.HTML(\"<p><i>‚ö´Ô∏è [Guild AI]: Compiling response...</i></p>\", layout={'display': 'none'})\n",
    "\n",
    "def display_message(who, message, is_html=False):\n",
    "    \"\"\"Appends a message to the chat history view.\"\"\"\n",
    "    \n",
    "    if is_html:\n",
    "        # If the message is already HTML, just add the sender info and display directly.\n",
    "        # This prevents wrapping the AI's markdown-converted HTML in another <p> tag.\n",
    "        color = \"green\"\n",
    "        icon = \"üü¢\"\n",
    "        formatted_message = f'<div style=\"margin-left: 5px;\"><p style=\"color:{color}; margin-bottom: 0px;\"><strong>{icon} [Guild AI]:</strong></p>{message}</div>'\n",
    "    else:\n",
    "        # For plain text messages (like the user's), wrap them in a <p> tag as before.\n",
    "        color = \"royalblue\"\n",
    "        icon = \"üîµ\"\n",
    "        formatted_message = f'<p style=\"color:{color}; margin-left: 5px;\"><strong>{icon} [{who}]:</strong> {message}</p>'\n",
    "    \n",
    "    # The IPython.display.HTML object is used to render the string as HTML\n",
    "    chat_history_view.append_display_data(HTML(formatted_message))\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "    .widget-text textarea { width: 100% !important; }\n",
    "    .widget-button button { background-color: #4CAF50 !important; color: white !important; }\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "print(\"‚úÖ  Chat Interface Initialized. Enter your prompt below.\")\n",
    "display(chat_history_view, widgets.HBox([prompt_input, send_button]), loading_spinner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b8cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Context Toolkit\n",
    "\n",
    "CONTEXT_FILES = {\n",
    "    \"manifesto\": \"_Admin & Core Docs/Protocols-Frameworks/GUILD_MANIFESTO.md\",\n",
    "    \"taxonomy\": \"_Admin & Core Docs/Protocols-Frameworks/taxonomy_framework.md\",\n",
    "    \"decomposition\": \"project_decomposition.md\",\n",
    "    \"op_protocols\": \"_Admin & Core Docs/Protocols-Frameworks/GUILD_OP_PROTOCOLS.md\",\n",
    "    \"registry\": \"_Admin & Core Docs/registry/operative_registry.json\"\n",
    "}\n",
    "\n",
    "def get_context(keyword):\n",
    "    \"\"\"Retrieves the content of a specific context file.\"\"\"\n",
    "    file_path = CONTEXT_FILES.get(keyword.lower())\n",
    "    if not file_path:\n",
    "        return f\"ERROR: Unknown context keyword '{keyword}'. Valid keywords are: {list(CONTEXT_FILES.keys())}\"\n",
    "    \n",
    "    try:\n",
    "        # Adjust pathing as needed\n",
    "        full_path = os.path.join(os.getcwd(), '..', file_path)\n",
    "        if not os.path.exists(full_path):\n",
    "             full_path = os.path.join(os.getcwd(), file_path)\n",
    "        \n",
    "        with open(full_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: Could not load file for '{keyword}': {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da284182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: UI Logic (The \"Backend\" for the UI)\n",
    "\n",
    "def on_send_button_clicked(b):\n",
    "    prompt = prompt_input.value\n",
    "    if not prompt.strip():\n",
    "        return # Do nothing if input is empty\n",
    "    \n",
    "    # Display the user's message and show loading spinner\n",
    "    display_message(\"Operative Kin-Caid\", prompt)\n",
    "    prompt_input.value = \"\" # Clear the input box\n",
    "    loading_spinner.layout.display = 'block'\n",
    "\n",
    "    final_prompt = prompt\n",
    "    \n",
    "    if prompt.strip().startswith('!context'):\n",
    "        parts = prompt.strip().split()\n",
    "        if len(parts) > 1:\n",
    "            keyword = parts[1]\n",
    "            context_content = get_context(keyword)\n",
    "            # Create a new prompt that includes the retrieved context\n",
    "            final_prompt = f\"\"\"\n",
    "            Here is the content of the '{keyword}' document for your reference:\n",
    "            ---\n",
    "            {context_content}\n",
    "            ---\n",
    "            Now, please answer my original question based on this new context: {prompt}\n",
    "            \"\"\"\n",
    "            display_message(\"SYSTEM\", f\"<i>Injecting context from '{keyword}'...</i>\") # Default to the user's original prompt\n",
    "    \n",
    "    try:\n",
    "        # Send message to the AI\n",
    "        response = guild_chat_session.send_message(final_prompt)\n",
    "        \n",
    "        # Display AI's response (using HTML to render markdown)\n",
    "        from markdown import markdown\n",
    "        html_response = markdown(response.text)\n",
    "        display_message(\"Guild AI\", html_response, is_html=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        display_message(\"SYSTEM\", f\"<strong>üî¥ ERROR:</strong> {e}\")\n",
    "    finally:\n",
    "        # Hide loading spinner\n",
    "        loading_spinner.layout.display = 'none'\n",
    "\n",
    "send_button.on_click(on_send_button_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5bdb16",
   "metadata": {},
   "source": [
    "Use these commands at the start of a chat to add context docs:\n",
    "\n",
    "!context manifesto\n",
    "!context taxonomy\n",
    "!context decomposition\n",
    "!context op_protocols\n",
    "!context registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c482c08",
   "metadata": {},
   "source": [
    "Use this to generate chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59233f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¥ ERROR saving history: [Errno 2] No such file or directory: 'chat_logs/portfolio_project_chat.json'\n"
     ]
    }
   ],
   "source": [
    "save_chat_history(guild_chat_session, 'chat_logs/portfolio_project_chat.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06157ed3-a7c2-4876-b386-7c254c30e32a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

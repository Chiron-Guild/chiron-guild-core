{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1cfb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 1: Setup & Initialization (Local Environment Version)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerativeai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgenai\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# --- Configuration ---\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Load environment variables from the .env file in the root directory\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup & Initialization (Local Environment Version)\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# --- Configuration ---\n",
    "# Load environment variables from the .env file in the root directory\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"üî¥ ERROR: GEMINI_API_KEY not found in .env file.\")\n",
    "    print(\"Please create a .env file in the repository root with GEMINI_API_KEY='your-key'.\")\n",
    "else:\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "# --- Guild Protocol Functions ---\n",
    "\n",
    "def load_system_instruction(protocol_file_path=\"_Admin & Core Docs/Protocols-Frameworks/Copilot_Context_Protocol.md\"):\n",
    "    \"\"\"Loads the Guild's core protocol document to be used as the system instruction.\"\"\"\n",
    "    try:\n",
    "        # Use os.path.join for cross-platform compatibility\n",
    "        full_path = os.path.join(os.getcwd(), '..', protocol_file_path) # Assumes notebook is in notebooks/\n",
    "        if not os.path.exists(full_path):\n",
    "             full_path = os.path.join(os.getcwd(), protocol_file_path) # Assumes notebook is in root\n",
    "        \n",
    "        with open(full_path, 'r', encoding='utf-8') as f:\n",
    "            print(f\"‚úÖ Protocol file found and loaded from: {full_path}\")\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"üî¥ ERROR: Protocol file not found.\")\n",
    "        print(\"Please ensure the path in the 'load_system_instruction' function is correct relative to the repository root.\")\n",
    "        return None\n",
    "\n",
    "def initialize_guild_chat(system_instruction):\n",
    "    \"\"\"Initializes a new chat session with the Guild's system instruction.\"\"\"\n",
    "    if not system_instruction:\n",
    "        return None\n",
    "    \n",
    "    generation_config = {\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 1,\n",
    "        \"top_k\": 32,\n",
    "        \"max_output_tokens\": 8192, # Increase the max token output significantly\n",
    "}\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-2.5-flash-preview-05-20\", # Corrected Model Name\n",
    "        system_instruction=system_instruction,\n",
    "        generation_config=generation_config\n",
    "    )\n",
    "    chat = model.start_chat()\n",
    "    return chat\n",
    "\n",
    "# --- Main Initialization Step ---\n",
    "print(\"üõ°Ô∏è  Initializing Guild Interface AI...\")\n",
    "guild_system_protocol = load_system_instruction()\n",
    "\n",
    "if guild_system_protocol:\n",
    "    guild_chat_session = initialize_guild_chat(guild_system_protocol)\n",
    "    if guild_chat_session:\n",
    "        print(\"‚úÖ  Initialization Complete. AI is calibrated to Guild Protocols.\")\n",
    "        print(\"‚û°Ô∏è  Proceed to run Cell 2 to begin the chat session.\")\n",
    "else:\n",
    "    print(\"üî¥  Initialization Failed. Please check errors above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: The Main Chat Loop\n",
    "\n",
    "# This check ensures that the notebook isn't run out of order.\n",
    "if 'guild_chat_session' not in locals() or not guild_chat_session:\n",
    "    print(\"üî¥ ERROR: Chat session not initialized. Please run Cell 1 first.\")\n",
    "else:\n",
    "    print(\"‚úÖ  Chat Session Active. Type 'exit' or 'quit' to end.\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Get input from the Operative\n",
    "            prompt = input(\"üîµ [Operative Kin-Caid]: \")\n",
    "\n",
    "            if prompt.lower() in ['exit', 'quit']:\n",
    "                print(\"‚ö´Ô∏è  [Guild AI]: Session terminated. Standby for new directive.\")\n",
    "                break\n",
    "\n",
    "            # Send the message to the Gemini model\n",
    "            print(\"‚ö´Ô∏è  [Guild AI]: Compiling response...\")\n",
    "            response = guild_chat_session.send_message(prompt)\n",
    "            \n",
    "            # Print the AI's response\n",
    "            print(f\"üü¢ [Guild AI]: {response.text}\")\n",
    "            print(\"-\" * 20)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚ö´Ô∏è  [Guild AI]: Kernel interrupted. Session terminated.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"üî¥ [ERROR]: An unexpected error occurred: {e}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fadd3d",
   "metadata": {},
   "source": [
    "2. The User Experience (How You Would Use It):\n",
    "You open the guild_interface_v1.ipynb notebook in JupyterLab or VS Code.\n",
    "You run the first cell (Setup & Initialization) once. This \"boots up\" your specialized AI assistant and loads it into memory.\n",
    "You run the second cell (The Main Chat Loop). It will display the [Operative Kin-Caid]: prompt and wait.\n",
    "You type your questions directly into the output of that cell.\n",
    "The conversation happens right there in the notebook's output. The while loop keeps it running, so you can have a long, continuous conversation.\n",
    "When you're done, you simply interrupt the kernel to stop the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da284182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc1d0272",
   "metadata": {},
   "source": [
    "Cell 1: Setup & Initialization\n",
    "This cell would contain all your imports (GoogleGenAI, etc.).\n",
    "It would define a function, let's call it initialize_guild_chat(). This function would:\n",
    "Read the entire Copilot_Context_Protocol.md file into a string.\n",
    "Create the ai instance: new GoogleGenAI(...).\n",
    "Create the \"primed\" chat instance: ai.chats.create({ systemInstruction: ... }).\n",
    "Return the chat object.\n",
    "\n",
    "Cell 2: The Main Chat Loop\n",
    "This cell would be the interactive part of your application. It would contain a while True: loop.\n",
    "Inside the loop, it would:\n",
    "Use Python's input() function to display a prompt like [Operative Kin-Caid]:.\n",
    "Wait for you to type your message and press Enter.\n",
    "Take your input and call chat.sendMessage({ message: your_input }).\n",
    "Get the response from the AI.\n",
    "Print the response to the screen, formatted nicely, e.g., [Guild AI]: response.text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup & Initialization\n",
    "\n",
    "import os\n",
    "from google.colab import userdata # Use this for Google Colab\n",
    "# If not in Colab, manage your API key via another method like python-dotenv\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "# --- Google AI Gemini API Setup ---\n",
    "# Note: The original prompt used a placeholder 'GoogleGenAI' which is often\n",
    "# an alias for the main library. The actual library is 'google.generativeai'.\n",
    "import google.generativeai as genai\n",
    "\n",
    "# --- Configuration ---\n",
    "# Ensure your API key is stored as a secret named 'GEMINI_API_KEY' in Colab\n",
    "# or is available as an environment variable.\n",
    "try:\n",
    "    # For Google Colab\n",
    "    api_key = userdata.get('GEMINI_API_KEY')\n",
    "except ImportError:\n",
    "    # For local environments (e.g., using python-dotenv)\n",
    "    api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"ERROR: GEMINI_API_KEY not found. Please set it as a secret or environment variable.\")\n",
    "else:\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "# --- Guild Protocol Functions ---\n",
    "\n",
    "def load_system_instruction(protocol_file_path=\"_Admin & Core Docs\\Protocols-Frameworks\\Copilot_Context_Protocol.md\"): \n",
    "    \"\"\"Loads the Guild's core protocol document to be used as the system instruction.\"\"\"\n",
    "    try:\n",
    "        with open(protocol_file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Protocol file not found at '{protocol_file_path}'.\")\n",
    "        print(\"Please ensure 'Copilot_Context_Protocol.md' is in the root directory.\")\n",
    "        return None\n",
    "\n",
    "def initialize_guild_chat(system_instruction):\n",
    "    \"\"\"Initializes a new chat session with the Guild's system instruction.\"\"\"\n",
    "    if not system_instruction:\n",
    "        return None\n",
    "    \n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-2.5-flash-preview-05-20\", # Using a recommended modern model\n",
    "        system_instruction=system_instruction\n",
    "    )\n",
    "    chat = model.start_chat()\n",
    "    return chat\n",
    "\n",
    "# --- Main Initialization Step ---\n",
    "print(\"üõ°Ô∏è  Initializing Guild Interface AI...\")\n",
    "guild_system_protocol = load_system_instruction()\n",
    "\n",
    "if guild_system_protocol:\n",
    "    guild_chat_session = initialize_guild_chat(guild_system_protocol)\n",
    "    if guild_chat_session:\n",
    "        print(\"‚úÖ  Initialization Complete. AI is calibrated to Guild Protocols.\")\n",
    "        print(\"‚û°Ô∏è  Proceed to run Cell 2 to begin the chat session.\")\n",
    "else:\n",
    "    print(\"üî¥  Initialization Failed. Please check errors above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: The Main Chat Loop\n",
    "\n",
    "# This check ensures that the notebook isn't run out of order.\n",
    "if 'guild_chat_session' not in locals() or not guild_chat_session:\n",
    "    print(\"üî¥ ERROR: Chat session not initialized. Please run Cell 1 first.\")\n",
    "else:\n",
    "    print(\"‚úÖ  Chat Session Active. Type 'exit' or 'quit' to end.\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Get input from the Operative\n",
    "            prompt = input(\"üîµ [Operative Kin-Caid]: \")\n",
    "\n",
    "            if prompt.lower() in ['exit', 'quit']:\n",
    "                print(\"‚ö´Ô∏è  [Guild AI]: Session terminated. Standby for new directive.\")\n",
    "                break\n",
    "\n",
    "            # Send the message to the Gemini model\n",
    "            print(\"‚ö´Ô∏è  [Guild AI]: Compiling response...\")\n",
    "            response = guild_chat_session.send_message(prompt)\n",
    "            \n",
    "            # Print the AI's response\n",
    "            print(f\"üü¢ [Guild AI]: {response.text}\")\n",
    "            print(\"-\" * 20)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚ö´Ô∏è  [Guild AI]: Kernel interrupted. Session terminated.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"üî¥ [ERROR]: An unexpected error occurred: {e}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fadd3d",
   "metadata": {},
   "source": [
    "2. The User Experience (How You Would Use It):\n",
    "You open the guild_interface_v1.ipynb notebook in JupyterLab or VS Code.\n",
    "You run the first cell (Setup & Initialization) once. This \"boots up\" your specialized AI assistant and loads it into memory.\n",
    "You run the second cell (The Main Chat Loop). It will display the [Operative Kin-Caid]: prompt and wait.\n",
    "You type your questions directly into the output of that cell.\n",
    "The conversation happens right there in the notebook's output. The while loop keeps it running, so you can have a long, continuous conversation.\n",
    "When you're done, you simply interrupt the kernel to stop the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da284182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
